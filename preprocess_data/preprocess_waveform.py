# -*- coding: utf-8 -*-
"""preprocess_waveform.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ItgU8rW0fPxQmG6vYa4wkpwmke0mqJnn
"""

# creates a pickle file of waveforms with associated labels

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
!pip install torch>=1.2.0
!pip install torchaudio
# %matplotlib inline
!pip install moviepy

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import Dataset
import torchaudio
import pandas as pd
import os
from google.colab import files
import pickle
import matplotlib.pyplot as plt
import moviepy.editor as mp 
import math

device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # see whether gpu can be used
print(device)

aud_list = [] # initialize a list for waveforms to be added
# iterate through the folder structure to convert .mp4 files to .wav, then convert to waveform
for obj in range(12):
    for mat in range(5):
        for root, dirs, files in os.walk("/content/gdrive/My Drive/fall/{}/{}/".format(obj,mat), topdown=False): # change directory as necessary
            for name in files:
                full_file_name = os.path.join(root, name) # file name of each file in this folder including the root
                if full_file_name.endswith("Camera_1.mp4"): # we only care about the Camera_1.mp4 file
                    clip = mp.VideoFileClip(r"{}".format(full_file_name))
                    clip.audio.write_audiofile(r"{}/Camera_1.wav".format(root)) # convert .mp4 to .wav
                    waveform, sample_rate = torchaudio.load("{}/Camera_1.wav".format(root)) # convert .wav to waveform
                    aud_list.append(waveform[0])

# since the videos vary in length, we pad the waveforms to match the longest video
aud_list_padded = [] # initialize a list of padded waveforms
for i in range(len(aud_list)):
    diff = 311787 - len(aud_list[i]) # 311787 is the length of the longest file; compute the difference between current file and longest file
    pad = torch.nn.functional.pad(aud_list[i], (math.floor(diff/2),math.ceil(diff/2)), mode='constant', value=0) # pad with appropriate number of zeros
    aud_list_padded.append(pad)

c
phys101_df['Sound'] = aud_list_padded # add a 'Sound' column with waveforms to dataframe
phys101_df.to_pickle("/content/gdrive/My Drive/phys101_waveform.pkl") # save to pickle for future use

# visualize one waveform
plt.figure()
plt.plot(aud_list_padded[0].t().numpy())
plt.xlabel('time step')
plt.ylabel('amplitude')